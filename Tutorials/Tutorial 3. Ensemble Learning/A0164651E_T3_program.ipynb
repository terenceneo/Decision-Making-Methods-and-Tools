{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from __future__ import division\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "%pwd\n",
    "train = pd.read_csv('./train.csv')\n",
    "# Tranform dataframe to array\n",
    "train_feature = train.iloc[:,1:].values\n",
    "train_target = train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-Fold Cross Validation\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single decision tree model: 0.8485238095238095\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Single decision tree model\n",
    "decision_tree = DecisionTreeClassifier(criterion='entropy', random_state=12345)\n",
    "\n",
    "# Cross validation on Model 1\n",
    "cv_model_1 = cross_val_score(decision_tree, # Cross-validation on Model 1\n",
    "                             train.iloc[:,1:], # Feature matrix\n",
    "                             train.iloc[:,0], # Output vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring='accuracy' # Model performance metrics: accuracy\n",
    "                            )\n",
    "\n",
    "# Report performance of Model 1\n",
    "print (\"Single decision tree model: %s\" %(cv_model_1.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging model: 0.9398333333333333\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Bagging method\n",
    "bagging = BaggingClassifier(n_estimators=100, random_state=12345)\n",
    "\n",
    "# Cross validation on Model 2\n",
    "cv_model_2 = cross_val_score(bagging, # Cross-validation on Model 2\n",
    "                             train.iloc[:,1:], # Feature matrix\n",
    "                             train.iloc[:,0], # Output vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring='accuracy' # Model performance metrics: accuracy\n",
    "                            )\n",
    "\n",
    "# Report performance of Model 2\n",
    "print(\"Bagging model: %s\" %(cv_model_2.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model: 0.9576190476190476\n"
     ]
    }
   ],
   "source": [
    "#Question 1. Create a random forest model (2 points)\n",
    "# Model 3: Random Forest method\n",
    "random_forest = RandomForestClassifier(criterion='entropy', n_estimators=100, random_state=12345)\n",
    "\n",
    "\n",
    "# Cross validation on Model 3\n",
    "cv_model_3 = cross_val_score(random_forest, # Cross-validation on Model 3\n",
    "                             train.iloc[:,1:], # Feature matrix\n",
    "                             train.iloc[:,0], # Output vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring='accuracy' # Model performance metrics: accuracy\n",
    "                            )\n",
    "\n",
    "# Report performance of Model 3\n",
    "print(\"Random Forest model: %s\" %(cv_model_3.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost model: 0.7053809523809524\n"
     ]
    }
   ],
   "source": [
    "#Question 2. Create an Adaboost model (2 points)\n",
    "# Model 4: AdaBoosting method\n",
    "Adaboost = AdaBoostClassifier(n_estimators=100, random_state=12345)\n",
    "\n",
    "# Cross validation on Model 4\n",
    "cv_model_4 = cross_val_score(Adaboost, # Cross-validation on Model 4\n",
    "                             train.iloc[:,1:], # Feature matrix\n",
    "                             train.iloc[:,0], # Output vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring='accuracy' # Model performance metrics: accuracy\n",
    "                            ) \n",
    "\n",
    "# Report performance of Model 4\n",
    "print(\"Adaboost model: %s\" %(cv_model_4.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3. Based on your results, what is your finding? (1 point)\n",
    "#The caategorization accuracy of the models are as follows:\n",
    "#decision_tree: 0.8485238095238095\n",
    "#bagging: 0.9398333333333333\n",
    "#random_forest: 0.9576190476190476\n",
    "#Adaboost: 0.7053809523809524\n",
    "#From the results, we can conclude that the random_forest model produces\n",
    "#the highest accuracy for this set of data, closely followed by the bagging model.\n",
    "#We may opt to use the bagging model instead if there is a significant save in\n",
    "#computational power required over the random_forest model.\n",
    "#The adaboost model on the other hand, has a far lower accuracy than even the\n",
    "#decision tree model and can be discarded based on its low accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
