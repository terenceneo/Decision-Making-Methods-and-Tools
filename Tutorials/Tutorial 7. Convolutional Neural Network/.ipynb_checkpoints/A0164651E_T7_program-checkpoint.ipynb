{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT2101 Deep Learning: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook should run in Python 3.5+ version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Goal\n",
    "\n",
    "In this notebook, we will explore deep learning and Convolutional Neural Network. <br/>\n",
    "\n",
    "First of all, students should understand machine learning basic knowledge. And then, students can expect to practice machine learning and deep learning models in Tensorflow. More information can be found at https://www.tensorflow.org/install/ and https://keras.io/.\n",
    "\n",
    "Make sure you have already installed tensorflow in your computing, and then you are able to install Keras. **Note that Tensorflow only supports Python 3.5+ version.** If you installed Python 2.7 version in your computer, you could:\n",
    "* Create a new virtual environment with Python 3.5+ in Anaconda \n",
    "* Activate this virtual environment\n",
    "* Install Tensorflow CPU version in this virtual environment\n",
    "* Open Python in this virtual environment and type `import tensorflow as tf`\n",
    "* Installation of Tensorflow succeeds if there is not error message returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# Set seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Check whether tensorflow is installed\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Experiment Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case I: Multi-class Classification Using Fully-Connected Neural Network\n",
    "\n",
    "**Remember in Tutorial 5, we contructed a fully-connected neural network model to do handwritten digit classification. Let us review it again.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to practice with handwritten digital from MINIST dataset, which is the representative data to explore machine learning techniques. We are going to practice to learn the basics of Keras by walking through a simple example: MINIST consists of $28\\times28$ grayscale images of handwritten digits like these:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*_4Ua9Zp84He8OxlZ4cy0DQ@2x.png\" width=\"500\">\n",
    "\n",
    "The dataset also includes labels for each image, telling us which digit it is. For example, the labels for the above images are 5, 0, 4, and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ths X data is a 3D Array (images, width, height) of grayscale values. To prepare the data for training, we should convert the 3D Array to matrices by reshaping width and height into a single dimension (i.e., $28\\times28$ images are flatterned into length 784 vectors). Then, we rescale the grayscale values from integers ranging between 0 to 255 into floating point values ranging between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = x_train.reshape(x_train.shape[0], 784) / 255\n",
    "x_test_new = x_test.reshape(x_test.shape[0], 784) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y data is an integer vector with values ranging from 0 to 9. To prepare this data for training we should encode the vectors into binary class matrices using the Keras function `to_categorical()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_new = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can try the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(units=256, activation='relu', input_dim=784))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=10, activation='sigmoid'))\n",
    "\n",
    "# The argument for the first layer specifies the shape of the input data (a length 784 numeric vector representing a grayscale image). \n",
    "# The final layer outputs a length 10 numeric vector (probabilities for each digit) using a softmax activation function.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some activation functions:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*p_hyqAtyI8pbt2kEl6siOQ.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can compile the model with appropriate loss function, optimizer and metrics \n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with 30 epochs and batches of 128 images\n",
    "history = model.fit(x_train_new, y_train_new, epochs=15, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on test data\n",
    "loss_and_metrics = model.evaluate(x_test_new, y_test_new, batch_size=128)\n",
    "loss_and_metrics #[loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "probabilities = model.predict(x_test_new, batch_size=128)\n",
    "classes = probabilities.argmax(axis=-1)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the first image in x_test_new look like\n",
    "# Whether we predict it correctly?\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(np.array(x_test_new[0,:]).reshape((28, 28)), cmap=\"gray\")\n",
    "plt.title(\"This digit is %d\" % classes[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(history.epoch, history.history['val_acc'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['acc'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case II: Multi-class Classification Using Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to practice with `Convolutional Neural Network`. You can compare it with fully-connected neural network model.\n",
    "\n",
    "References: https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import keras\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 28*28*1 and normalize to [0, 1]\n",
    "x_train_new = x_train.reshape(x_train.shape[0], 28, 28, 1) / 255\n",
    "x_test_new = x_test.reshape(x_test.shape[0], 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the categorical output label into 10 binary output labels\n",
    "y_train_new = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_new = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model in a sequential way\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and convolution layer (with 32 different filters/kernels, each filter/kernel is 5*5 dimension)\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\n",
    "# Pooling layer: Maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Set dropout rate to 0.2\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flattern all pixels/neurons and generate a fully-connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=10, activation='sigmoid'))\n",
    "\n",
    "# The argument for the first layer specifies the shape of the input data (a length 784 numeric vector representing a grayscale image). \n",
    "# The final layer outputs a length 10 numeric vector (probabilities for each digit) using a softmax activation function.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can compile the model with appropriate loss function, optimizer and metrics \n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with 15 epochs and batches of 128 images\n",
    "history = model.fit(x_train_new, y_train_new, epochs=15, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on test data\n",
    "loss_and_metrics = model.evaluate(x_test_new, y_test_new, batch_size=128)\n",
    "loss_and_metrics #[loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see that test accuracy of CNN model is close to 99%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "probabilities = model.predict(x_test_new, batch_size=128)\n",
    "classes = probabilities.argmax(axis=-1)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the first image in x_test_new look like\n",
    "# Whether we predict it correctly?\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(np.array(x_test_new[0,:]).reshape((28, 28)), cmap=\"gray\")\n",
    "plt.title(\"This digit is %d\" % classes[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(history.epoch, history.history['val_acc'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['acc'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "# References: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Number {}\".format(i) for i in range(10)]\n",
    "print(classification_report(y_test, classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is your turn. Read Tensorflow and Keras documents and examples on deep learning model. Familiarize yourself with applications of convolutional neural network models. \n",
    "\n",
    "References: https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Assignments (5 points)\n",
    "\n",
    "### Purpose: Familiarize yourself with Building Convolutional Neural Network Models in Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset on Hand Writen Digits: The same dataset used in Tutorial 3 Ensemble Learning. Remember in tutorials 3 and 5, the accuracy of single decision tree model is about 86%, bagging model 95%, random forest model 96%, fully-connected neural network model 95%. Let us check the performance of convolutional neural network model\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "The Kaggle competition dataset can be obtained from https://www.kaggle.com/c/digit-recognizer/data.\n",
    "\n",
    "**Overview:**\n",
    "\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.\n",
    "\n",
    "**Acknowlegements:**\n",
    "\n",
    "More details about the dataset, including algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html. The dataset is made available under a Creative Commons Attribution-Share Alike 3.0 license.\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
    "\n",
    "The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import keras\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset: You need to download dataset first\n",
    "%pwd\n",
    "train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 42,000 pictures; Each picture is composed of 28*28 dimensional pixels\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does an image look like\n",
    "plt.imshow(np.array(train.iloc[1,1:]).reshape((28, 28)), cmap=\"gray\")\n",
    "plt.title(\"This digit is %d\" % train.iloc[1,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features and outputs\n",
    "# Convert X to 28*28*1 and normalize to [0, 1]\n",
    "train_feature = train.iloc[:,1:].values.reshape(train.shape[0], 28, 28, 1) / 255\n",
    "\n",
    "# Binarize output labels\n",
    "train_target = keras.utils.to_categorical(train.iloc[:,0], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1. Create a convolutional neural network model, and show model performance (3 points)\n",
    "\n",
    "#### Hint:\n",
    "* Create a neural network in a sequential way\n",
    "* Set the first convolutional layer Conv2D with 36 filters/kernels, while each filter/kernel is 3\\*3 dimention: `Conv2D(36, (3, 3))`, `activation='relu'`, `input_shape=(28, 28, 1)`\n",
    "* Set a maxpooling layer with 3\\*3 dimension patches: `MaxPooling2D(pool_size=(3, 3))`\n",
    "* Set another convolutional layer Conv2D with 24 filters/kernels, while each filter/kernel is 2\\*2 dimention: `Conv2D(24, (2, 2))`, `activation='relu'`\n",
    "* Set another maxpooling layer Conv2D with 2\\*2 dimension patches: `MaxPooling2D(pool_size=(2, 2))`\n",
    "* Set dropout rate to 0.1\n",
    "* Flattern all pixels/neurons using `Flatten()`\n",
    "* Generate a fully-connected layer with parameters: `units=128, activation='relu'`\n",
    "* Generate another fully-connected layer with parameters: `units=50, activation='relu'`\n",
    "* Set output layer with parameters: `units=10`, `activation='sigmoid'`\n",
    "* Train the model with parameters: `epochs=20`, `batch_size=128`, `validation_split=0.3`\n",
    "* Compile the model with parameters: `loss='categorical_crossentropy'`, `optimizer='sgd'`, `metrics=['accuracy']`\n",
    "* Sample code:\n",
    "\n",
    "```python\n",
    "\n",
    "# Build CNN model in a sequential way\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and convolution layer (with 32 different filters/kernels, each filter/kernel is 5*5 dimension)\n",
    "model.add(Conv2D(32, (7, 7), input_shape=(28, 28, 1), activation='relu'))\n",
    "\n",
    "# Pooling layer: Maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Set dropout rate to 0.2\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flattern all pixels/neurons \n",
    "model.add(Flatten())\n",
    "\n",
    "# Generate a fully-connected layer with 128 pixels/neurons\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=10, activation='sigmoid'))\n",
    "\n",
    "# The argument for the first layer specifies the shape of the input data (a length 784 numeric vector representing a grayscale image). \n",
    "# The final layer outputs a length 10 numeric vector (probabilities for each digit) using a softmax activation function.\n",
    "model.summary()\n",
    "\n",
    "# Then we can compile the model with appropriate loss function, optimizer and metrics \n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model with 30 epochs and batches of 128 images\n",
    "history = model.fit(x_train_new, y_train_new, epochs=30, batch_size=128, validation_split=0.3)\n",
    "\n",
    "# Evaluate model performance on test data\n",
    "loss_and_metrics = model.evaluate(x_test_new, y_test_new, batch_size=128)\n",
    "loss_and_metrics #[loss, accuracy]\n",
    "\n",
    "```\n",
    "\n",
    "References: https://keras.io/activations/ and https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can try the sequential model\n",
    "# Create a neural network in a sequential way\n",
    "model = Sequential()\n",
    "\n",
    "# Set the first convolutional layer Conv2D with 36 filters/kernels, while each filter/kernel is 3*3 dimention: \n",
    "# Conv2D(36, (3, 3)), activation='relu', input_shape=(28, 28, 1)\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set a maxpooling layer with 3*3 dimension patches: MaxPooling2D(pool_size=(3, 3))\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set another convolutional layer Conv2D with 24 filters/kernels, while each filter/kernel is 2*2 dimention: \n",
    "# Conv2D(24, (2, 2)), activation='relu'\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set another maxpooling layer Conv2D with 2*2 dimension patches: MaxPooling2D(pool_size=(2, 2))\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set dropout rate to 0.1\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "# Flattern all pixels/neurons using Flatten()\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "# Generate a fully-connected layer with parameters: units=128, activation='relu'\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "# Generate another fully-connected layer with parameters: units=50, activation='relu'\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "# Set output layer with parameters: units=10, activation='sigmoid'\n",
    "# Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The argument for the first layer specifies the shape of the input data (a length 784 numeric vector representing a grayscale image). \n",
    "# The final layer outputs a length 10 numeric vector (probabilities for each digit) using a sigmoid activation function.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can compile the model with appropriate loss function, optimizer and metrics \n",
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with 30 epochs and batches of 128 images\n",
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on train data\n",
    "loss_and_metrics = model.evaluate(train_feature, train_target, batch_size=128)\n",
    "loss_and_metrics #[loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(history.epoch, history.history['val_acc'], 'g-', label='Validation data')\n",
    "plt.plot(history.epoch, history.history['acc'], 'r--', label='Training data')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy on training/validation data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Predictions on the test data (1 point)\n",
    "\n",
    "#### Hint:\n",
    "\n",
    "* Predict class labels using `predict` function\n",
    "* Sample code:\n",
    "\n",
    "```python\n",
    "\n",
    "# Make predictions on test data\n",
    "probabilities = model.predict(x_test_new, batch_size=128)\n",
    "classes = probabilities.argmax(axis=-1)\n",
    "classes\n",
    "\n",
    "```\n",
    "\n",
    "References: https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test dataset\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "# Transform features\n",
    "test_feature = test.values.reshape(test.shape[0], 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "# Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the first image in test_feature look like\n",
    "# Whether do we predict it correctly?\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(np.array(test_feature[0]).reshape((28, 28)), cmap=\"gray\")\n",
    "plt.title(\"This digit is %d\" % classes[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. Why do we need to use pooling (or subsampling) in CNN, such as maxpooling? (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 References\n",
    "[1] Chris Albon. (2018). Machine Learning with Python Cookbook. O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
